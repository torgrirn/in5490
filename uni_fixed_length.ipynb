{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/kmsravindra/ML-AI-experiments/blob/master/AI/Neural%20Machine%20Translation/Neural%20machine%20translation%20-%20Encoder-Decoder%20seq2seq%20model.ipynb\n",
    "import os\n",
    "\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\"\"\"\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=1\n",
    "train_path = \"training_sets_split/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  trained_models/13.13.18_13:04_unidirectional  Created \n",
      "Directory  trained_models/13.13.18_13:04_unidirectional/weights  Created \n",
      "Directory  trained_models/13.13.18_13:04_unidirectional/samples  Created \n",
      "Directory  trained_models/13.13.18_13:04_unidirectional/history  Created \n"
     ]
    }
   ],
   "source": [
    "network = \"unidirectional\"\n",
    "datatype = \"normal, transposed to A minor and C major\"\n",
    "stride = 4\n",
    "encoder_dropout = False\n",
    "decoder_dropout = True\n",
    "dropout_encoder_amount = 0.2\n",
    "dropout_decoder_amount = 0.2\n",
    "\n",
    "timestamp = strftime(\"%d.%d.%y_%H:%M\", gmtime())\n",
    "folder_name = \"trained_models/\"+timestamp+\"_\"+network\n",
    "weights_folder_name = folder_name + \"/weights\"\n",
    "samples_folder_name = folder_name + \"/samples\"\n",
    "history_folder_name = folder_name + \"/history\"\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(folder_name)\n",
    "    print(\"Directory \" , folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , folder_name ,  \" already exists\")\n",
    "    \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(weights_folder_name)\n",
    "    print(\"Directory \" , weights_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , weights_folder_name ,  \" already exists\")\n",
    "    \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(samples_folder_name)\n",
    "    print(\"Directory \" , samples_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , samples_folder_name ,  \" already exists\")\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(history_folder_name)\n",
    "    print(\"Directory \" , history_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , history_folder_name ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training inputs 8962\n",
      "Number of training targets 8962\n",
      "Input example: [ 60 129 129 129  67 129 129 129  64 129 129 129  60 129 129 129  67 129\n",
      " 129 129  69 129 129 129  69 129 129 129  67 129 129 129]\n",
      "Target example: [ 55 129 129 129  55 129 129 129  55 129 129 129  57 129 129 129  60 129\n",
      " 129 129  65 129 129 129  65 129 129 129  64 129 129 129]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and create pairs of inputs and targets\n",
    "\n",
    "with np.load(train_path+'split_inputs.npz') as split_inputs:\n",
    "    inputs = split_inputs['train']\n",
    "    \n",
    "with np.load(train_path+'split_targets.npz') as split_targets:\n",
    "    targets = split_targets['train']\n",
    "\n",
    "print(\"Number of training inputs\",len(inputs))\n",
    "print(\"Number of training targets\",len(targets))\n",
    "\n",
    "# Print examples of inputs and targets\n",
    "example_in = inputs[0]\n",
    "example_target = targets[0]\n",
    "print(\"Input example:\", example_in)\n",
    "print(\"Target example:\", example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set\n",
    "with np.load(train_path+'split_test_inputs.npz') as test_inputs:\n",
    "    test_soprano_tenor = test_inputs['train']\n",
    "with np.load(train_path+'split_test_targets.npz') as test_targets:\n",
    "    test_alto_bass = test_targets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make set of unique notes\n",
    "split_inputs_uniq = np.unique(inputs)\n",
    "split_targets_uniq = np.unique(targets)\n",
    "test_soprano_tenor_uniq = np.unique(test_soprano_tenor)\n",
    "test_alto_bass_uniq = np.unique(test_alto_bass)\n",
    "input_set = set()\n",
    "target_set = set()\n",
    "for note in split_inputs_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "for note in split_targets_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "for note in test_soprano_tenor_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "for note in test_alto_bass_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "#target_set.add(200)\n",
    "#target_set.add(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of input notes:\n",
      " [31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 128, 129]\n",
      "Set of target notes:\n",
      " [31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 128, 129]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = list(inputs)\n",
    "target_sequences = []\n",
    "#input_set = set()\n",
    "#target_set = set()\n",
    "num_samples = len(inputs)\n",
    "    \n",
    "for i in range(num_samples):    \n",
    "    target_with_tokens = list(targets[i]) \n",
    "    target_sequences.append(target_with_tokens)\n",
    "\n",
    "            \n",
    "input_set = sorted(list(input_set))\n",
    "target_set = sorted(list(target_set))\n",
    "print(\"Set of input notes:\\n\", input_set)\n",
    "print(\"Set of target notes:\\n\", target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each input note - key is index and value is the note\n",
    "input_index_to_note_dict = {}\n",
    "\n",
    "# dictionary to get note given its index - key is the note and value is the index\n",
    "input_note_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(input_set):\n",
    "    input_index_to_note_dict[k] = v\n",
    "    input_note_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each target note - key is index and value is the note\n",
    "target_index_to_note_dict = {}\n",
    "\n",
    "# dictionary to get note given its index - key is the note and value is the index\n",
    "target_note_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(target_set):\n",
    "    target_index_to_note_dict[k] = v\n",
    "    target_note_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "max_len_inputs = max([len(seq) for seq in input_sequences])\n",
    "max_len_targets = max([len(line) for line in target_sequences])\n",
    "print(max_len_inputs)\n",
    "print(max_len_targets)\n",
    "\n",
    "doc = []\n",
    "doc.append(\"Network type:\\t\\t\\t\"+network)\n",
    "doc.append(\"Dataset type:\\t\\t\\t\"+datatype)\n",
    "\n",
    "if encoder_dropout:\n",
    "    doc.append(\"Encoder dropout:\\t\\t{}\".format(dropout_encoder_amount))\n",
    "if decoder_dropout:\n",
    "    doc.append(\"Decoder dropout:\\t\\t{}\".format(dropout_decoder_amount))\n",
    "\n",
    "doc.append(\"Batch size:\\t\\t\\t{}\".format(batch_size))\n",
    "doc.append(\"Sample length:\\t\\t\\t{}\".format(max_len_inputs))\n",
    "doc.append(\"Stride:\\t\\t\\t\\t{}\".format(stride))\n",
    "doc.append(\"Number of training inputs:\\t{}\".format(len(inputs)))\n",
    "doc.append(\"Number of training targets:\\t{}\".format(len(targets)))\n",
    "noteset = ' '.join(str(value) for value in input_set)\n",
    "doc.append(\"Set of notes:\\n \" + noteset)\n",
    "\n",
    "\n",
    "file = open(folder_name + \"/Specifications.txt\", \"w\")\n",
    "file.write(\"\\n\".join(doc))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input_sequences = np.zeros(shape=(num_samples,max_len_inputs,len(input_set)), dtype='float32')\n",
    "tokenized_target_sequences = np.zeros(shape=(num_samples,max_len_targets,len(target_set)), dtype='float32')\n",
    "target_data = np.zeros((num_samples, max_len_targets, len(target_set)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    for k, note_value in enumerate(input_sequences[i]):\n",
    "        tokenized_input_sequences[i,k,input_note_to_index_dict[note_value]] = 1\n",
    "    \n",
    "    for k, note_value in enumerate(target_sequences[i]):\n",
    "        tokenized_target_sequences[i,k,target_note_to_index_dict[note_value]] = 1\n",
    "        \n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1, target_note_to_index_dict[note_value]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "\n",
    "encoder_input = Input(shape=(None,len(input_set)))\n",
    "\n",
    "if encoder_dropout:\n",
    "    encoder_LSTM = LSTM(256,return_state = True, recurrent_dropout=dropout_encoder_amount)\n",
    "else:\n",
    "    encoder_LSTM = LSTM(256,return_state = True)\n",
    "\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "\n",
    "decoder_input = Input(shape=(None,len(target_set)))\n",
    "\n",
    "if decoder_dropout:\n",
    "    decoder_LSTM = LSTM(256,return_sequences=True, return_state = True, recurrent_dropout=dropout_decoder_amount)\n",
    "else:\n",
    "    decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(target_set),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=weights_folder_name+\"/{epoch:02d}-loss_{loss:.2f}-val_loss_{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, mode='min', save_best_only=False)\n",
    "callbacks_list = [checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7169 samples, validate on 1793 samples\n",
      "Epoch 1/1\n",
      "7169/7169 [==============================] - 37s 5ms/step - loss: 1.6872 - val_loss: 1.3150\n",
      "\n",
      "Epoch 00001: saving model to trained_models/13.13.18_13:04_unidirectional/weights/01-loss_1.69-val_loss_1.31.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torgrim/anaconda3/lib/python3.5/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[tokenized_input_sequences,tokenized_target_sequences], \n",
    "          y=target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss and validation loss\n",
    "loss = np.array(history.history['loss'])\n",
    "validation_loss = np.array(history.history['val_loss'])\n",
    "loss_name = history_folder_name+'/loss.npz'\n",
    "val_loss_name = history_folder_name+'/validation_loss.npz'\n",
    "np.savez(loss_name, loss=loss)\n",
    "np.savez(val_loss_name, loss=validation_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with np.load(loss_name) as data:\n",
    "    loss = list(data['loss'])\n",
    "    \n",
    "with np.load(val_loss_name) as data:\n",
    "    val_loss = list(data['loss'])\n",
    "\n",
    "epoch = np.arange(epochs)\n",
    "\n",
    "plt.plot(epoch, loss, label=\"Training loss\", color=\"blue\", linewidth=1, linestyle=\"-\")    # Add labels for the legend\n",
    "plt.plot(epoch, val_loss, label=\"Validation loss\", color=\"red\", linewidth=1, linestyle=\"-\")    # Add labels for the legend\n",
    "plt.xlabel('Epoch')   # Add labels for the axis\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "#model.load_weights(\"unidirectional.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\" helper function to sample an index from a probability array\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq, input_length, temperature=1.0):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "   \n",
    "    target_seq = np.zeros((1, 1, len(target_set)))\n",
    "    #target_seq[0, 0, target_note_to_index_dict[200]] = 1\n",
    "\n",
    "    decoded_sequence = []\n",
    "    stop_condition = False\n",
    "    input_seq_length = len(inp_seq)\n",
    "    \n",
    "    while not stop_condition:       \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        #max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        \n",
    "        # Sample with temperature\n",
    "        max_val_index = sample(decoder_out[0,-1,:], temperature=1.2)\n",
    "        sampled_note = target_index_to_note_dict[max_val_index]\n",
    "        decoded_sequence.append(sampled_note)\n",
    "        \n",
    "        if len(decoded_sequence) == input_length:\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(target_set)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]   \n",
    "    return np.array(decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "temperature=1.2\n",
    "\n",
    "# Sample with soprano and tenor from test set\n",
    "\n",
    "with np.load(train_path+'test_inputs.npz') as test_targets:\n",
    "    test_soprano_tenor = test_targets['train']\n",
    "    \n",
    "max_len_test_soprano_tenor = max([len(seq) for seq in test_soprano_tenor])\n",
    "tokenized_inputs_sop_ten = np.zeros(shape=(len(test_soprano_tenor),max_len_test_soprano_tenor,len(input_set)), dtype='float32')  \n",
    "    \n",
    "for i in range(len(test_soprano_tenor)):\n",
    "    for k, note_value in enumerate(test_soprano_tenor[i]):\n",
    "        tokenized_inputs_sop_ten[i,k,input_note_to_index_dict[note_value]] = 1 \n",
    "\n",
    "\n",
    "# Save all samples as file.\n",
    "# Input sequences on even index and decoded sequences on odd index\n",
    "\n",
    "samples = []\n",
    "for seq_index, seq in enumerate(test_soprano_tenor):\n",
    "    if seq_index % 10 == 0:\n",
    "        print(seq_index)\n",
    "    inp_seq = tokenized_inputs_sop_ten[seq_index:seq_index+1]\n",
    "    input_seq_length = len(seq)\n",
    "    decoded_sequence = decode_seq(inp_seq, input_seq_length, temperature)\n",
    "    samples.append(test_soprano_tenor[seq_index])\n",
    "    samples.append(decoded_sequence)\n",
    "samples = np.array(samples)\n",
    "np.savez(samples_folder_name+'/sampled_soprano_tenor_temperature{}.npz'.format(temperature), samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Sample with alto and bass from test set\n",
    "\n",
    "with np.load(train_path+'test_targets.npz') as test_targets:\n",
    "    test_alto_bass = test_targets['train']\n",
    "\n",
    "max_len_test_alto_bass = max([len(seq) for seq in test_alto_bass])\n",
    "tokenized_inputs_alt_bas = np.zeros(shape=(len(test_alto_bass),max_len_test_alto_bass,len(input_set)), dtype='float32')  \n",
    "    \n",
    "for i in range(len(test_soprano_tenor)):\n",
    "    for k, note_value in enumerate(test_alto_bass[i]):\n",
    "        tokenized_inputs_alt_bas[i,k,input_note_to_index_dict[note_value]] = 1 \n",
    "\n",
    "\n",
    "# Save all samples as file.\n",
    "# Input sequences on even index and decoded sequences on odd index\n",
    "\n",
    "#folder_name = \"/home/torgrim/master/IN5490/model/in5490/ferdig_trent/Session_normal_dataset_unidirectional_09.09.18_17_38\"\n",
    "\n",
    "samples = []\n",
    "for seq_index, seq in enumerate(test_alto_bass):\n",
    "    if seq_index % 10 == 0:\n",
    "        print(seq_index)\n",
    "    inp_seq = tokenized_inputs_alt_bas[seq_index:seq_index+1]\n",
    "    input_seq_length = len(seq)\n",
    "    decoded_sequence = decode_seq(inp_seq, input_seq_length, temperature)\n",
    "    samples.append(test_alto_bass[seq_index])\n",
    "    samples.append(decoded_sequence)\n",
    "samples = np.array(samples)\n",
    "np.savez(samples_folder_name+'/sampled_alto_bass_temperature{}.npz'.format(temperature), samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
