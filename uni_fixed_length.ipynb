{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/kmsravindra/ML-AI-experiments/blob/master/AI/Neural%20Machine%20Translation/Neural%20machine%20translation%20-%20Encoder-Decoder%20seq2seq%20model.ipynb\n",
    "import os\n",
    "\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\"\"\"\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=3\n",
    "train_path = \"training_sets_split/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  trained_models/13.13.18_11:12_unidirectional  Created \n",
      "Directory  trained_models/13.13.18_11:12_unidirectional/weights  Created \n",
      "Directory  trained_models/13.13.18_11:12_unidirectional/samples  Created \n",
      "Directory  trained_models/13.13.18_11:12_unidirectional/history  Created \n"
     ]
    }
   ],
   "source": [
    "network = \"unidirectional\"\n",
    "datatype = \"normal, transposed to A minor and C major\"\n",
    "stride = 4\n",
    "encoder_dropout = False\n",
    "decoder_dropout = True\n",
    "dropout_encoder_amount = 0.2\n",
    "dropout_decoder_amount = 0.2\n",
    "\n",
    "timestamp = strftime(\"%d.%d.%y_%H:%M\", gmtime())\n",
    "folder_name = \"trained_models/\"+timestamp+\"_\"+network\n",
    "weights_folder_name = folder_name + \"/weights\"\n",
    "samples_folder_name = folder_name + \"/samples\"\n",
    "history_folder_name = folder_name + \"/history\"\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(folder_name)\n",
    "    print(\"Directory \" , folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , folder_name ,  \" already exists\")\n",
    "    \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(weights_folder_name)\n",
    "    print(\"Directory \" , weights_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , weights_folder_name ,  \" already exists\")\n",
    "    \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(samples_folder_name)\n",
    "    print(\"Directory \" , samples_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , samples_folder_name ,  \" already exists\")\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(history_folder_name)\n",
    "    print(\"Directory \" , history_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , history_folder_name ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training inputs 8962\n",
      "Number of training targets 8962\n",
      "Input example: [ 60 129 129 129  67 129 129 129  64 129 129 129  60 129 129 129  67 129\n",
      " 129 129  69 129 129 129  69 129 129 129  67 129 129 129]\n",
      "Target example: [ 55 129 129 129  55 129 129 129  55 129 129 129  57 129 129 129  60 129\n",
      " 129 129  65 129 129 129  65 129 129 129  64 129 129 129]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and create pairs of inputs and targets\n",
    "\n",
    "with np.load(train_path+'split_inputs.npz') as split_inputs:\n",
    "    inputs = split_inputs['train']\n",
    "    \n",
    "with np.load(train_path+'split_targets.npz') as split_targets:\n",
    "    targets = split_targets['train']\n",
    "\n",
    "print(\"Number of training inputs\",len(inputs))\n",
    "print(\"Number of training targets\",len(targets))\n",
    "\n",
    "# Print examples of inputs and targets\n",
    "example_in = inputs[0]\n",
    "example_target = targets[0]\n",
    "print(\"Input example:\", example_in)\n",
    "print(\"Target example:\", example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set\n",
    "with np.load(train_path+'split_test_inputs.npz') as test_inputs:\n",
    "    test_soprano_tenor = test_inputs['train']\n",
    "with np.load(train_path+'split_test_targets.npz') as test_targets:\n",
    "    test_alto_bass = test_targets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make set of unique notes\n",
    "split_inputs_uniq = np.unique(inputs)\n",
    "split_targets_uniq = np.unique(targets)\n",
    "test_soprano_tenor_uniq = np.unique(test_soprano_tenor)\n",
    "test_alto_bass_uniq = np.unique(test_alto_bass)\n",
    "input_set = set()\n",
    "target_set = set()\n",
    "for note in split_inputs_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "for note in split_targets_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "for note in test_soprano_tenor_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "for note in test_alto_bass_uniq:\n",
    "    input_set.add(note)\n",
    "    target_set.add(note)\n",
    "#target_set.add(200)\n",
    "#target_set.add(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of input notes:\n",
      " [31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 128, 129]\n",
      "Set of target notes:\n",
      " [31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 128, 129]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = list(inputs)\n",
    "target_sequences = []\n",
    "#input_set = set()\n",
    "#target_set = set()\n",
    "num_samples = len(inputs)\n",
    "    \n",
    "for i in range(num_samples):    \n",
    "    target_with_tokens = list(targets[i]) \n",
    "    target_sequences.append(target_with_tokens)\n",
    "\n",
    "            \n",
    "input_set = sorted(list(input_set))\n",
    "target_set = sorted(list(target_set))\n",
    "print(\"Set of input notes:\\n\", input_set)\n",
    "print(\"Set of target notes:\\n\", target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each input note - key is index and value is the note\n",
    "input_index_to_note_dict = {}\n",
    "\n",
    "# dictionary to get note given its index - key is the note and value is the index\n",
    "input_note_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(input_set):\n",
    "    input_index_to_note_dict[k] = v\n",
    "    input_note_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each target note - key is index and value is the note\n",
    "target_index_to_note_dict = {}\n",
    "\n",
    "# dictionary to get note given its index - key is the note and value is the index\n",
    "target_note_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(target_set):\n",
    "    target_index_to_note_dict[k] = v\n",
    "    target_note_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "max_len_inputs = max([len(seq) for seq in input_sequences])\n",
    "max_len_targets = max([len(line) for line in target_sequences])\n",
    "print(max_len_inputs)\n",
    "print(max_len_targets)\n",
    "\n",
    "doc = []\n",
    "doc.append(\"Network type:\\t\\t\\t\"+network)\n",
    "doc.append(\"Dataset type:\\t\\t\\t\"+datatype)\n",
    "\n",
    "if encoder_dropout:\n",
    "    doc.append(\"Encoder dropout:\\t\\t{}\".format(dropout_encoder_amount))\n",
    "if decoder_dropout:\n",
    "    doc.append(\"Decoder dropout:\\t\\t{}\".format(dropout_decoder_amount))\n",
    "\n",
    "doc.append(\"Batch size:\\t\\t\\t{}\".format(batch_size))\n",
    "doc.append(\"Sample length:\\t\\t\\t{}\".format(max_len_inputs))\n",
    "doc.append(\"Stride:\\t\\t\\t\\t{}\".format(stride))\n",
    "doc.append(\"Number of training inputs:\\t{}\".format(len(inputs)))\n",
    "doc.append(\"Number of training targets:\\t{}\".format(len(targets)))\n",
    "noteset = ' '.join(str(value) for value in input_set)\n",
    "doc.append(\"Set of notes:\\n \" + noteset)\n",
    "\n",
    "\n",
    "file = open(folder_name + \"/Specifications.txt\", \"w\")\n",
    "file.write(\"\\n\".join(doc))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input_sequences = np.zeros(shape=(num_samples,max_len_inputs,len(input_set)), dtype='float32')\n",
    "tokenized_target_sequences = np.zeros(shape=(num_samples,max_len_targets,len(target_set)), dtype='float32')\n",
    "target_data = np.zeros((num_samples, max_len_targets, len(target_set)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    for k, note_value in enumerate(input_sequences[i]):\n",
    "        tokenized_input_sequences[i,k,input_note_to_index_dict[note_value]] = 1\n",
    "    \n",
    "    for k, note_value in enumerate(target_sequences[i]):\n",
    "        tokenized_target_sequences[i,k,target_note_to_index_dict[note_value]] = 1\n",
    "        \n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1, target_note_to_index_dict[note_value]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "\n",
    "encoder_input = Input(shape=(None,len(input_set)))\n",
    "\n",
    "if encoder_dropout:\n",
    "    encoder_LSTM = LSTM(256,return_state = True, recurrent_dropout=dropout_encoder_amount)\n",
    "else:\n",
    "    encoder_LSTM = LSTM(256,return_state = True)\n",
    "\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "\n",
    "decoder_input = Input(shape=(None,len(target_set)))\n",
    "\n",
    "if decoder_dropout:\n",
    "    decoder_LSTM = LSTM(256,return_sequences=True, return_state = True, recurrent_dropout=dropout_decoder_amount)\n",
    "else:\n",
    "    decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(target_set),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=weights_folder_name+\"/{epoch:02d}-loss_{loss:.2f}-val_loss_{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, mode='min', save_best_only=False)\n",
    "callbacks_list = [checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7169 samples, validate on 1793 samples\n",
      "Epoch 1/3\n",
      "7169/7169 [==============================] - 53s 7ms/step - loss: 1.6961 - val_loss: 1.3161\n",
      "\n",
      "Epoch 00001: saving model to trained_models/13.13.18_11:12_unidirectional/weights/01-loss_1.70-val_loss_1.32.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torgrim/anaconda3/lib/python3.5/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "7169/7169 [==============================] - 53s 7ms/step - loss: 1.3510 - val_loss: 1.2261\n",
      "\n",
      "Epoch 00002: saving model to trained_models/13.13.18_11:12_unidirectional/weights/02-loss_1.35-val_loss_1.23.hdf5\n",
      "Epoch 3/3\n",
      "7169/7169 [==============================] - 47s 6ms/step - loss: 1.1851 - val_loss: 1.1202\n",
      "\n",
      "Epoch 00003: saving model to trained_models/13.13.18_11:12_unidirectional/weights/03-loss_1.19-val_loss_1.12.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[tokenized_input_sequences,tokenized_target_sequences], \n",
    "          y=target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss and validation loss\n",
    "loss = np.array(history.history['loss'])\n",
    "validation_loss = np.array(history.history['val_loss'])\n",
    "loss_name = history_folder_name+'/loss.npz'\n",
    "val_loss_name = history_folder_name+'/validation_loss.npz'\n",
    "np.savez(loss_name, loss=loss)\n",
    "np.savez(val_loss_name, loss=validation_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with np.load(loss_name) as data:\n",
    "    loss = list(data['loss'])\n",
    "    \n",
    "with np.load(val_loss_name) as data:\n",
    "    val_loss = list(data['loss'])\n",
    "\n",
    "epoch = np.arange(epochs)\n",
    "\n",
    "plt.plot(epoch, loss, label=\"Training loss\", color=\"blue\", linewidth=1, linestyle=\"-\")    # Add labels for the legend\n",
    "plt.plot(epoch, val_loss, label=\"Validation loss\", color=\"red\", linewidth=1, linestyle=\"-\")    # Add labels for the legend\n",
    "plt.xlabel('Epoch')   # Add labels for the axis\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "#model.load_weights(\"unidirectional.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq, input_length):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "   \n",
    "    target_seq = np.zeros((1, 1, len(target_set)))\n",
    "    #target_seq[0, 0, target_note_to_index_dict[200]] = 1\n",
    "\n",
    "    decoded_sequence = []\n",
    "    stop_condition = False\n",
    "    input_seq_length = len(inp_seq)\n",
    "    \n",
    "    while not stop_condition:       \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)      \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_note = target_index_to_note_dict[max_val_index]\n",
    "        decoded_sequence.append(sampled_note)\n",
    "        \n",
    "        if len(decoded_sequence) == input_length:\n",
    "        #if ((sampled_note == 201) or (len(decoded_sequence) > max_len_targets)):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(target_set)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]   \n",
    "    return np.array(decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "[ 69 129 129 129  69 129 129 129  69 129 129 129  76 129 129 129 129 129\n",
      "  74 129  72 129 129 129  76 129 129 129  74 129 129 129  72 129 129 129\n",
      "  71 129 129 129 129 129 129 129 129 129 129 129  76 129 129 129  76 129\n",
      " 129 129  78 129 129 129  79 129 129 129 129 129 129 129  78 129 129 129\n",
      "  76 129 129 129  75 129 129 129 129 129 129 129  76 129 129 129 129 129\n",
      " 129 129 129 129 129 129  76 129 129 129  74 129 129 129  71 129 129 129\n",
      "  72 129 129 129 129 129  74 129  76 129 129 129  74 129 129 129  72 129\n",
      " 129 129]\n",
      "[129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n",
      " 129 129]\n"
     ]
    }
   ],
   "source": [
    "# Sample with soprano and tenor from test set\n",
    "\n",
    "with np.load(train_path+'test_inputs.npz') as test_targets:\n",
    "    test_soprano_tenor = test_targets['train']\n",
    "    \n",
    "max_len_test_soprano_tenor = max([len(seq) for seq in test_soprano_tenor])\n",
    "tokenized_inputs_sop_ten = np.zeros(shape=(len(test_soprano_tenor),max_len_test_soprano_tenor,len(input_set)), dtype='float32')  \n",
    "    \n",
    "for i in range(len(test_soprano_tenor)):\n",
    "    for k, note_value in enumerate(test_soprano_tenor[i]):\n",
    "        tokenized_inputs_sop_ten[i,k,input_note_to_index_dict[note_value]] = 1 \n",
    "\n",
    "\n",
    "# Save all samples as file.\n",
    "# Input sequences on even index and decoded sequences on odd index\n",
    "\n",
    "samples = []\n",
    "for seq_index, seq in enumerate(test_soprano_tenor):\n",
    "    if seq_index % 10 == 0:\n",
    "        print(seq_index)\n",
    "    inp_seq = tokenized_inputs_sop_ten[seq_index:seq_index+1]\n",
    "    input_seq_length = len(seq)\n",
    "    decoded_sequence = decode_seq(inp_seq, input_seq_length)\n",
    "    samples.append(test_soprano_tenor[seq_index])\n",
    "    samples.append(decoded_sequence)\n",
    "samples = np.array(samples)\n",
    "np.savez(samples_folder_name+'/sampled_soprano_tenor.npz', samples=samples)\n",
    "print(samples[0])\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# Sample with alto and bass from test set\n",
    "\n",
    "with np.load(train_path+'test_targets.npz') as test_targets:\n",
    "    test_alto_bass = test_targets['train']\n",
    "\n",
    "max_len_test_alto_bass = max([len(seq) for seq in test_alto_bass])\n",
    "tokenized_inputs_alt_bas = np.zeros(shape=(len(test_alto_bass),max_len_test_alto_bass,len(input_set)), dtype='float32')  \n",
    "    \n",
    "for i in range(len(test_soprano_tenor)):\n",
    "    for k, note_value in enumerate(test_alto_bass[i]):\n",
    "        tokenized_inputs_alt_bas[i,k,input_note_to_index_dict[note_value]] = 1 \n",
    "\n",
    "\n",
    "# Save all samples as file.\n",
    "# Input sequences on even index and decoded sequences on odd index\n",
    "\n",
    "#folder_name = \"/home/torgrim/master/IN5490/model/in5490/ferdig_trent/Session_normal_dataset_unidirectional_09.09.18_17_38\"\n",
    "\n",
    "samples = []\n",
    "for seq_index, seq in enumerate(test_alto_bass):\n",
    "    if seq_index % 10 == 0:\n",
    "        print(seq_index)\n",
    "    inp_seq = tokenized_inputs_alt_bas[seq_index:seq_index+1]\n",
    "    input_seq_length = len(seq)\n",
    "    decoded_sequence = decode_seq(inp_seq, input_seq_length)\n",
    "    samples.append(test_alto_bass[seq_index])\n",
    "    samples.append(decoded_sequence)\n",
    "samples = np.array(samples)\n",
    "np.savez(samples_folder_name+'/sampled_alto_bass.npz', samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
