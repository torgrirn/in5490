{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/kmsravindra/ML-AI-experiments/blob/master/AI/Neural%20Machine%20Translation/Neural%20machine%20translation%20-%20Encoder-Decoder%20seq2seq%20model.ipynb\n",
    "import os\n",
    "\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\"\"\"\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  trained_models/transposed_dataset_07.07.18_13:22  Created \n",
      "Directory  trained_models/transposed_dataset_07.07.18_13:22/weights  Created \n"
     ]
    }
   ],
   "source": [
    "session_name = \"Session_normal_dataset\"\n",
    "timestamp = strftime(\"%d.%d.%y_%H:%M\", gmtime())\n",
    "folder_name = session_name+\"_\"+timestamp\n",
    "\n",
    "folder_name = \"trained_models/\"+session_name+\"_\"+timestamp\n",
    "weights_folder_name = folder_name + \"/weights\"\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(folder_name)\n",
    "    print(\"Directory \" , folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , folder_name ,  \" already exists\")\n",
    "    \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(weights_folder_name)\n",
    "    print(\"Directory \" , weights_folder_name ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , weights_folder_name ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training inputs 324\n",
      "Number of training targets 324\n",
      "Input example: [129 129 129 129 129 129 129 129 129 129 129 129  72 129 129 129  71 129\n",
      " 129 129  69 129 129 129  67 129 129 129  67 129 129 129]\n",
      "Target example: [129 129 129 129 129 129 129 129 129 129 129 129  67 129 129 129  67 129\n",
      " 129 129  66 129 129 129  62 129 129 129  64 129  62 129]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and create pairs of inputs and targets\n",
    "\n",
    "with np.load('split_inputs.npz') as split_inputs:\n",
    "    inputs = split_inputs['train']\n",
    "    \n",
    "with np.load('split_targets.npz') as split_targets:\n",
    "    targets = split_targets['train']\n",
    "\n",
    "print(\"Number of training inputs\",len(inputs))\n",
    "print(\"Number of training targets\",len(targets))\n",
    "\n",
    "# Print examples of inputs and targets\n",
    "example_in = inputs[0]\n",
    "example_target = targets[0]\n",
    "print(\"Input example:\", example_in)\n",
    "print(\"Target example:\", example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62 129  60 ... 129 129 129]\n",
      " [129  60 129 ... 129 129  60]\n",
      " [ 60 129  58 ... 129  60 129]\n",
      " ...\n",
      " [129 129 129 ... 129 129  59]\n",
      " [129 129  55 ... 129  59 129]\n",
      " [129  55 129 ...  59 129 129]]\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "with np.load('split_test_inputs.npz') as test_input:\n",
    "    test_inputs = test_input['test']\n",
    "with np.load('split_test_targets.npz') as test_target:\n",
    "    test_targets = test_target['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of input notes:\n",
      " [53, 55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 129]\n",
      "Set of target notes:\n",
      " [43, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 129, 200, 201]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "input_sequences = list(inputs)\n",
    "target_sequences = []\n",
    "input_set = set()\n",
    "target_set = set()\n",
    "num_samples = len(inputs)\n",
    "    \n",
    "for i in range(num_samples):    \n",
    "    target_with_tokens = [200] + list(targets[i]) + [201] # use 200 as start token and 201 as end token\n",
    "    target_sequences.append(target_with_tokens)\n",
    "    \n",
    "    # Add unique notes to set of notes\n",
    "    for item in input_sequences[i]:\n",
    "        if (item not in input_set):\n",
    "            input_set.add(item)\n",
    "    \n",
    "    for item in target_with_tokens:\n",
    "        if (item not in target_set):\n",
    "            target_set.add(item)\n",
    "            \n",
    "input_set = sorted(list(input_set))\n",
    "target_set = sorted(list(target_set))\n",
    "print(\"Set of input notes:\\n\", input_set)\n",
    "print(\"Set of target notes:\\n\", target_set)\n",
    "print(len(input_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each input note - key is index and value is the note\n",
    "input_index_to_note_dict = {}\n",
    "\n",
    "# dictionary to get note given its index - key is the note and value is the index\n",
    "input_note_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(input_set):\n",
    "    input_index_to_note_dict[k] = v\n",
    "    input_note_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each target note - key is index and value is the note\n",
    "target_index_to_note_dict = {}\n",
    "\n",
    "# dictionary to get note given its index - key is the note and value is the index\n",
    "target_note_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(target_set):\n",
    "    target_index_to_note_dict[k] = v\n",
    "    target_note_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "max_len_inputs = max([len(seq) for seq in input_sequences])\n",
    "max_len_targets = max([len(line) for line in target_sequences])\n",
    "print(max_len_inputs)\n",
    "print(max_len_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input_sequences = np.zeros(shape=(num_samples,max_len_inputs,len(input_set)), dtype='float32')\n",
    "tokenized_target_sequences = np.zeros(shape=(num_samples,max_len_targets,len(target_set)), dtype='float32')\n",
    "target_data = np.zeros((num_samples, max_len_targets, len(target_set)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    for k, note_value in enumerate(input_sequences[i]):\n",
    "        tokenized_input_sequences[i,k,input_note_to_index_dict[note_value]] = 1\n",
    "    \n",
    "    for k, note_value in enumerate(target_sequences[i]):\n",
    "        tokenized_target_sequences[i,k,target_note_to_index_dict[note_value]] = 1\n",
    "        \n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1, target_note_to_index_dict[note_value]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "\n",
    "encoder_input = Input(shape=(None,len(input_set)))\n",
    "encoder_LSTM = Bidirectional(LSTM(256,return_state = True))\n",
    "encoder_outputs, encoder_h_forward, encoder_c_forward, encoder_h_back, encoder_c_back = encoder_LSTM (encoder_input)\n",
    "\n",
    "# Concatenate forward states and backward states\n",
    "encoder_h = Concatenate()([encoder_h_forward, encoder_h_back])\n",
    "encoder_c = Concatenate()([encoder_c_forward, encoder_c_back])\n",
    "#encoder_h = concatenate([encoder_h_forward, encoder_h_back])\n",
    "#encoder_c = concatenate([encoder_c_forward, encoder_c_back])\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bidirectional_1/while/Exit_2:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"bidirectional_1/while_1/Exit_2:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"concatenate_1/concat:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"concatenate_2/concat:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_h_forward)\n",
    "print(encoder_h_back)\n",
    "\n",
    "print(encoder_h)\n",
    "print(encoder_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "\n",
    "decoder_input = Input(shape=(None,len(target_set)))\n",
    "\n",
    "# 512 because of concatenated forward states and backward states\n",
    "decoder_LSTM = LSTM(256*2,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(target_set),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=weights_folder_name+\"/{epoch:02d}-{mean_squared_error:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='mean_squared_error', verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 259 samples, validate on 65 samples\n",
      "Epoch 1/10\n",
      "259/259 [==============================] - 5s 19ms/step - loss: 3.0223 - mean_squared_error: 0.0386 - val_loss: 2.4509 - val_mean_squared_error: 0.0353\n",
      "\n",
      "Epoch 00001: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/01-0.04.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torgrim/anaconda3/lib/python3.5/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_1/concat:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "259/259 [==============================] - 3s 10ms/step - loss: 2.1782 - mean_squared_error: 0.0316 - val_loss: 2.1711 - val_mean_squared_error: 0.0233\n",
      "\n",
      "Epoch 00002: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/02-0.03.hdf5\n",
      "Epoch 3/10\n",
      "259/259 [==============================] - 3s 11ms/step - loss: 2.1906 - mean_squared_error: 0.0247 - val_loss: 1.4100 - val_mean_squared_error: 0.0219\n",
      "\n",
      "Epoch 00003: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/03-0.02.hdf5\n",
      "Epoch 4/10\n",
      "259/259 [==============================] - 3s 12ms/step - loss: 1.5161 - mean_squared_error: 0.0229 - val_loss: 1.1665 - val_mean_squared_error: 0.0187\n",
      "\n",
      "Epoch 00004: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/04-0.02.hdf5\n",
      "Epoch 5/10\n",
      "259/259 [==============================] - 3s 10ms/step - loss: 1.3497 - mean_squared_error: 0.0201 - val_loss: 1.1125 - val_mean_squared_error: 0.0187\n",
      "\n",
      "Epoch 00005: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/05-0.02.hdf5\n",
      "Epoch 6/10\n",
      "259/259 [==============================] - 3s 11ms/step - loss: 1.3309 - mean_squared_error: 0.0201 - val_loss: 1.0986 - val_mean_squared_error: 0.0184\n",
      "\n",
      "Epoch 00006: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/06-0.02.hdf5\n",
      "Epoch 7/10\n",
      "259/259 [==============================] - 3s 13ms/step - loss: 1.3111 - mean_squared_error: 0.0198 - val_loss: 1.1314 - val_mean_squared_error: 0.0186\n",
      "\n",
      "Epoch 00007: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/07-0.02.hdf5\n",
      "Epoch 8/10\n",
      "259/259 [==============================] - 3s 13ms/step - loss: 1.3149 - mean_squared_error: 0.0200 - val_loss: 1.1392 - val_mean_squared_error: 0.0185\n",
      "\n",
      "Epoch 00008: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/08-0.02.hdf5\n",
      "Epoch 9/10\n",
      "259/259 [==============================] - 3s 11ms/step - loss: 1.3044 - mean_squared_error: 0.0198 - val_loss: 1.1392 - val_mean_squared_error: 0.0185\n",
      "\n",
      "Epoch 00009: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/09-0.02.hdf5\n",
      "Epoch 10/10\n",
      "259/259 [==============================] - 3s 12ms/step - loss: 1.3006 - mean_squared_error: 0.0199 - val_loss: 1.1329 - val_mean_squared_error: 0.0185\n",
      "\n",
      "Epoch 00010: saving model to trained_models/transposed_dataset_07.07.18_13:22/weights/10-0.02.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ab7288a20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mean_squared_error'])\n",
    "model.fit(x=[tokenized_input_sequences,tokenized_target_sequences], \n",
    "          y=target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256*2,))\n",
    "decoder_state_input_c = Input(shape=(256*2,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq, input_length):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "   \n",
    "    target_seq = np.zeros((1, 1, len(target_set)))\n",
    "    target_seq[0, 0, target_note_to_index_dict[200]] = 1\n",
    "\n",
    "    decoded_sequence = []\n",
    "    stop_condition = False\n",
    "    input_seq_length = len(inp_seq)\n",
    "    \n",
    "    while not stop_condition:       \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)      \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_note = target_index_to_note_dict[max_val_index]\n",
    "        decoded_sequence.append(sampled_note)\n",
    "        \n",
    "        if ((sampled_note == 201) or (len(decoded_sequence) == input_length)):\n",
    "        #if ((sampled_note == 201) or (len(decoded_sequence) > max_len_targets)):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(target_set)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]   \n",
    "    return np.array(decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4a01c5dade6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtokenized_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_note_to_index_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 128"
     ]
    }
   ],
   "source": [
    "with np.load('split_test_inputs.npz') as data:\n",
    "    test_data = data['test']\n",
    "# Only if using the inputs from training set and some notes are missing\n",
    "#test_data = test_data[0:len(test_data):2]\n",
    "\n",
    "max_len_test_data = max([len(seq) for seq in test_data])\n",
    "tokenized_inputs = np.zeros(shape=(len(test_data),max_len_test_data,len(input_set)), dtype='float32')  \n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    for k, note_value in enumerate(test_data[i]):\n",
    "        tokenized_inputs[i,k,input_note_to_index_dict[note_value]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n",
      "Input sequence length: 32\n",
      "Decoded sequence length: 32\n"
     ]
    }
   ],
   "source": [
    "# Save all samples as file.\n",
    "# Input sequences on even index and decoded sequences on odd index\n",
    "\n",
    "folder_name = \"samples\"\n",
    "\n",
    "samples = []\n",
    "for seq_index, seq in enumerate(test_data):\n",
    "    inp_seq = tokenized_inputs[seq_index:seq_index+1]\n",
    "    input_seq_length = len(seq)\n",
    "    decoded_sequence = decode_seq(inp_seq, input_seq_length)\n",
    "    samples.append(test_data[seq_index])\n",
    "    samples.append(decoded_sequence)\n",
    "samples = np.array(samples)\n",
    "np.savez(folder_name+'/sampled_soprano_tenor.npz', samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('split_test_targets.npz') as data:\n",
    "    test_data = data['test']\n",
    "# Only if using the inputs from training set and some notes are missing\n",
    "#test_data = test_data[0:len(test_data):2]\n",
    "\n",
    "max_len_test_data = max([len(seq) for seq in test_data])\n",
    "tokenized_inputs = np.zeros(shape=(len(test_data),max_len_test_data,len(input_set)), dtype='float32')  \n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    for k, note_value in enumerate(test_data[i]):\n",
    "        tokenized_inputs[i,k,input_note_to_index_dict[note_value]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all samples as file.\n",
    "# Input sequences on even index and decoded sequences on odd index\n",
    "\n",
    "folder_name = \"samples\"\n",
    "\n",
    "samples = []\n",
    "for seq_index, seq in enumerate(test_data):\n",
    "    inp_seq = tokenized_inputs[seq_index:seq_index+1]\n",
    "    input_seq_length = len(seq)\n",
    "    decoded_sequence = decode_seq(inp_seq, input_seq_length)\n",
    "    samples.append(test_data[seq_index])\n",
    "    samples.append(decoded_sequence)\n",
    "samples = np.array(samples)\n",
    "np.savez(folder_name+'/sampled_alto_bass.npz', samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "b = np.array([99,22,45])\n",
    "c = np.unique(a)\n",
    "s = set()\n",
    "for i in c:\n",
    "    s.add(i)\n",
    "print(s)\n",
    "ll = np.array(list(s))\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
